{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "078803b9-923e-4a15-b12b-2e26881ff627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import threading\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b6e0347d-5dbb-4395-b8f5-7e4306cbf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bs\n",
    "# r = requests.get(url)\n",
    "\n",
    "# if r.status_code == requests.codes.ok:\n",
    "#     soup = bs(r.text, \"html.parser\")\n",
    "#     # print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a30f36cc-672f-4b53-8831-7358d4e4a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crawler:\n",
    "    def __init__(self):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")  # To run Chrome in headless mode\n",
    "        chrome_options.add_argument(\"--disable-gpu\")  # Required for Windows\n",
    "        self.driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    def getSoup(self, url, locator):\n",
    "        self.driver.get(url)\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(EC.presence_of_element_located(locator), \"not found\")\n",
    "        except:\n",
    "            print(\"locator not found\")\n",
    "        htmlContent = self.driver.page_source\n",
    "\n",
    "        soup = bs(htmlContent, 'html.parser')\n",
    "        return soup\n",
    "    \n",
    "    def getSoupWithButton(self, url, locator, button):\n",
    "        self.driver.get(url)\n",
    "        WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, button)), \"not found\")\n",
    "        print(\"clicking button\")\n",
    "        while True:\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, button)), \"not found\")\n",
    "                buttonElement = self.driver.find_element(By.CLASS_NAME, button)\n",
    "                WebDriverWait(self.driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, button)), \"not found\")\n",
    "                self.driver.execute_script(\"arguments[0].click();\", buttonElement)\n",
    "            except Exception as e:\n",
    "                break\n",
    "        print(\"finished\")\n",
    "        WebDriverWait(self.driver, 10).until(EC.presence_of_element_located(locator), \"not found\")\n",
    "        htmlContent = self.driver.page_source\n",
    "\n",
    "        soup = bs(htmlContent, 'html.parser')\n",
    "        return soup\n",
    "        \n",
    "    def quit(self):\n",
    "        self.driver.quit()\n",
    "        # print(\"end service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d19a7190-4b05-414e-96b9-5b5ec156bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllCompetition(crawler):\n",
    "    button = \"bh-more-block\"\n",
    "    locator = (By.CLASS_NAME, \"bh-card-item\")\n",
    "    soup = crawler.getSoupWithButton(url, locator, button)\n",
    "\n",
    "    print(\"start parsing\")\n",
    "    \n",
    "    competitions = {\"competitions\":[]} # {\"competition:[{title:t, ...},...]\"}\n",
    "    tags = []\n",
    "    relations = []\n",
    "\n",
    "    threads = []\n",
    "    semaphore = threading.Semaphore(2)\n",
    "    lock = threading.Lock()\n",
    "    containers = soup.find_all(\"div\", class_=\"bh-wrapper\")\n",
    "    for c in containers:\n",
    "        com = {}\n",
    "    \n",
    "        # get title and link\n",
    "        title = c.find(\"a\", class_=\"bh-title\")\n",
    "        if title == None:\n",
    "            continue\n",
    "        link = title.get(\"href\")\n",
    "        com[\"title\"] = title.text\n",
    "        # print(com[\"title\"])\n",
    "        \n",
    "        # get prize (total, highiest)\n",
    "        prizeBlock = c.find(\"div\", class_=\"bh-prize-block\")\n",
    "        if prizeBlock == None:\n",
    "            continue\n",
    "        prize = prizeBlock.find_all(\"span\", class_=\"bh-amount\")\n",
    "        for inx, p in enumerate(prize):\n",
    "            amount = re.sub(r\"\\D\", \"\", p.text)\n",
    "            if(amount == \"\"): continue\n",
    "            if(inx >= 1): com[\"highiestPrize\"] = int(amount)\n",
    "            else: com[\"totalPrize\"] = int(amount)\n",
    "\n",
    "        # get time\n",
    "        timeline = c.find(\"span\", class_=\"bh-item is-processing\")\n",
    "        if not timeline:\n",
    "            continue\n",
    "        com[\"dueTime\"] = timeline.text\n",
    "\n",
    "        # go to the competition page and get tags, relations\n",
    "        comUrl = genCompetitionUrl(baseUrl, link)\n",
    "        thread = threading.Thread(target=getOneCompetition, args=(comUrl, tags, relations, title.text, semaphore, lock))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        \n",
    "        com[\"link\"] = comUrl\n",
    "\n",
    "        # add the competition info\n",
    "        competitions[\"competitions\"].append(com)\n",
    "        \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    print(\"finished\")\n",
    "    \n",
    "    return competitions, tags, relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bed4c68c-9baa-4d2f-be9c-276eff59b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCompetitionUrl(baseUrl, link): \n",
    "    pattern = r\"(?<=competitions).+\"\n",
    "    id = re.findall(pattern, link)\n",
    "    id = id[0] if id else None\n",
    "    comUrl = baseUrl+id\n",
    "    return comUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6f74f520-dd97-4330-b75c-dfa818760d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneCompetition(url, curTags, relations, title, semaphore, lock):\n",
    "    semaphore.acquire()\n",
    "    \n",
    "    crawler = Crawler()\n",
    "    locator = (By.CSS_SELECTOR, \".bh-block.bh-content-block\")\n",
    "    soup = crawler.getSoup(url, locator)   \n",
    "    crawler.quit()\n",
    "\n",
    "    containers = soup.find_all(\"div\", class_=\"bh-block bh-category-tag-block\")\n",
    "    if len(containers) != 1:\n",
    "        print(\"sth wrong\")\n",
    "        semaphore.release()\n",
    "        return\n",
    "        \n",
    "    c = containers[0]\n",
    "    tags = c.find_all(\"a\", class_=\"bh-value\")\n",
    "    lock.acquire()\n",
    "    for t in tags:\n",
    "        relations.append([t.text, title])\n",
    "        if t.text not in curTags:\n",
    "            # print(t.text)\n",
    "            curTags.append(t.text)\n",
    "    lock.release()\n",
    "    semaphore.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "87222915-cc74-486b-960d-bb2ff26cd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDataAsCSV(data, header, fileName):\n",
    "    try:\n",
    "        with open(fileName, \"w\", newline=\"\") as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(header)\n",
    "            csvwriter.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def saveDataAsJson(filename, data):\n",
    "    with open(filename, 'w') as jsonFile:\n",
    "        json.dump(data, jsonFile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f86bf79e-ef2a-4940-8f8f-6078c250c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl = \"https://bhuntr.com/tw/competitions\"\n",
    "cate = \"?category=111,112\"\n",
    "url = baseUrl #  + cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7bbffc1a-7c54-4818-ae71-92ede7d71fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicking button\n",
      "finished\n",
      "start parsing\n",
      "locator not found\n",
      "sth wrong\n",
      "locator not found\n",
      "sth wrong\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "crawler = Crawler()\n",
    "\n",
    "competitions, tags, relations = getAllCompetition(crawler)\n",
    "\n",
    "crawler.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b0000865-7b6d-4fe6-b633-351bd925f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the files\n",
    "tagsShaped = [[t] for t in tags]\n",
    "saveDataAsCSV(tagsShaped, [\"tagName\"], \"tags.csv\")\n",
    "\n",
    "saveDataAsCSV(relations, [\"tagName\", \"competitionTitle\"], \"relations.csv\")\n",
    "\n",
    "saveDataAsJson(\"competitions.json\", competitions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
